# Embodied Emulated Personas

A project space for Embodied Emulated Personas - Embodied neural networks trained by LLM chatbot teachers.

LLM chatbots exhibit pseudo-embodiment in their prompt induced emulated personas. These personas can be very intelligent and learn from experience. They behave as if they were embodied based on the textual description of scenarios, although they aren't and they generally struggle in understanding physical spaces and mechanical common sense.

It is possible to hook these chatbots to virtual or physical bodies, similarly as they use other tools. They can be given a textual description of what their sensors perceive, and they can be asked to output their actions in forms which can be projected into motor control or other proper actions.

All the above is the current state of the art, as shown for example here: https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/

Getting from that point to true embodiment can be done for example as follows:
- Design a neural agent which is embodied.
- Hook up the LLM chatbot to this body, and let it perform a lot of tasks in that body and environment.
- Train the neural agent with imitation learning based on the LLM chatbot teaching.

## How To Take Part

Join the Discord server and introduce yourself. Then do what you want. PRs and Wiki contributions are welcome.

## Links

- Discord server: https://discord.com/invite/hzD7NDz8sY

All this started from this musing: https://www.linkedin.com/feed/update/urn:li:activity:7034227075800576001/
